<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-04-25T22:12:35-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Running with Hedgeclippers</title><subtitle>A website dedicated to adapting NLP techniques for the ever evolving needs of the modern world</subtitle><entry><title type="html">Convolutional Neural Networks for Text Classification: Part 1</title><link href="http://localhost:4000/cnns/2020/04/16/Max-Pooling.html" rel="alternate" type="text/html" title="Convolutional Neural Networks for Text Classification: Part 1" /><published>2020-04-16T00:00:00-04:00</published><updated>2020-04-16T00:00:00-04:00</updated><id>http://localhost:4000/cnns/2020/04/16/Max-Pooling</id><content type="html" xml:base="http://localhost:4000/cnns/2020/04/16/Max-Pooling.html">&lt;h1 id=&quot;cnns-for-nlp&quot;&gt;CNNs for NLP&lt;/h1&gt;

&lt;h3 id=&quot;a-story&quot;&gt;A Story:&lt;/h3&gt;

&lt;p&gt;There was a period of time in my life where I worked as a carpenter for a hostel in Taiwan. The building had a full woodshop on the 4th floor with a table saw in the middle of the room. One day the owner came upstairs and found me using a circular saw when he remarked I should use the table saw because it was safer. I had been avoiding the table saw because typically these saws were a lot stronger than handheld versions. There are horror stories in every woodshop about pieces of wood impaling or seriously injuring woodworkers after it was kicked back by one of these 2000 lbs behemoths. When I told him this, he showed me that the table saw was actually a homemade version, made from the same brand and model of the skil-saw I had in my hand. After that whenever I walked passed a construction site I would always notice the same setup. There would always be a strong piece of plywood screwed to two wood horses with the saw mounted upside down so its blade faced upwards. While a layman would never thought of this, these carpenters were experts in their craft and thus could find unique ways to leverage the resources they have. Understanding how their tools worked, allowed these carpenters to create a better, more jobsite appropriate version of a different saw.&lt;/p&gt;

&lt;p&gt;One of cooler things about Neural Nets is that as you advance you learn to employ different architectures for specific kinds of tasks. In this way, neural network architectures are one of the most powerful tools a DL/ML/CL engineer can use. So like the carpenters in Taiwan, learning the nuances of my tools is important for leveraging their full capabilities. Text is generally handled with recurrent models but there has been significant progress in using convolutional neural networks for certain tasks. For my continued research into fake news detection, I have been working on CNNs. For this reason I will be reviewing some of the material that is specific to CNNs. I will be adding more posts regarding CNNs as I look into different topics along the way.&lt;/p&gt;

&lt;h3 id=&quot;pooling-and-max-pooling&quot;&gt;Pooling and Max Pooling&lt;/h3&gt;
&lt;p&gt;During training for text classification, sentences are converted into 2-D representations of text. These represenations take the form of matrices where each row represents a word and each column an embedding dimension. Kernels of different heights are passed over these matrices which then produce a lower dimensional output. The height of these kernels essentially represents n-gram length and help to capture local information which for text tends to correspond to syntactic relationships. One of the problems of these inputs and the results of kernel multiplication is that they can have hundreds of dimensions. In our case hundreds of columns that don’t necessarily add much to the model but increase computational complexity significantly. In order to mitigate this, pooling is used to downsample these matrices. Max pooling specifically is the process of running a smaller dimensional kernel over an input and taking the largest values from the space the kernel is going over. There are different versions of pooling such as average pooling but the general idea is the same.&lt;/p&gt;

&lt;h3 id=&quot;example&quot;&gt;Example:&lt;/h3&gt;
&lt;p&gt;In this example we have 4 x 4 matrix representing our input and 2 x 2 filter with a stride of 2. In each case you can see that the kernel results in a smaller matrix with the maximum values taken at each step.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/MaxpoolSample2.png&quot; alt=&quot;Convolution Example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Source: https://computersciencewiki.org/index.php/Max-pooling_/_Pooling&lt;/p&gt;</content><author><name></name></author><summary type="html">CNNs for NLP</summary></entry><entry><title type="html">Better Docs Part 1: Tweepy Error Handling</title><link href="http://localhost:4000/better/docs/2020/04/10/Better-Docs-Tweepy-1.html" rel="alternate" type="text/html" title="Better Docs Part 1: Tweepy Error Handling" /><published>2020-04-10T19:13:00-04:00</published><updated>2020-04-10T19:13:00-04:00</updated><id>http://localhost:4000/better/docs/2020/04/10/Better-Docs-Tweepy-1</id><content type="html" xml:base="http://localhost:4000/better/docs/2020/04/10/Better-Docs-Tweepy-1.html">&lt;h1 id=&quot;better-docs-part-1&quot;&gt;Better Docs Part 1&lt;/h1&gt;
&lt;p&gt;Opensource software is incredibly important for modern programmers. The software is important and yet it often is only maintained by a few core developers. One of the problems of this is that documentation isn’t always maintained that well which can lead to countless hours spent learning the nuances of libraries that could have been spent on the problem itself. This series will serve to highlight some of things I come across while dealing with different libraries.&lt;/p&gt;

&lt;h3 id=&quot;tweepy-error-handling&quot;&gt;Tweepy Error Handling&lt;/h3&gt;
&lt;p&gt;The python Tweepy module is a useful for library for sending requests to Twitter’s search API. For those gathering significant amount of tweets, handling rate limits properly is important for streamlining continuos crawling. One of the problems with the Tweepy module is that errors are handled in the TweepyError class. Accessing error codes from these TweepyError instances isn’t outlined clearly in the Tweepy documentation. The tweepy API class also provides some error handling, however this requires enumerating all of the codes you wish to accept. Using a limiter wrapper around a cursor object I do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Python&quot;&gt;def limiter_tweepy_error_handler(cursor)
        while 1:
            try:
                yield cursor.next()
            except tw.TweepError as e:
                errors_list = eval(e.response.text)
                errors_list = errors_list['errors']
                codes = set()
                for error in errors_list:
                    codes.add(error[&quot;code&quot;])
                if codes in (429, 88):
                    print('Rate Limit Error Waiting 15 mins')
                    time.sleep(15*60)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The error message can be accessed as a dictionary through the &lt;code class=&quot;highlighter-rouge&quot;&gt;response&lt;/code&gt; attribute of the TweepError. I used the code above to specifically wait for 15 mins based on two separate error codes. This could obviously be extended to mitigate the limitations Twitter puts on this free service.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.twitter.com/en/docs/basics/response-codes&quot;&gt;You can check out the twitter error codes here as well &lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Better Docs Part 1 Opensource software is incredibly important for modern programmers. The software is important and yet it often is only maintained by a few core developers. One of the problems of this is that documentation isn’t always maintained that well which can lead to countless hours spent learning the nuances of libraries that could have been spent on the problem itself. This series will serve to highlight some of things I come across while dealing with different libraries.</summary></entry><entry><title type="html">REST Architecture Review</title><link href="http://localhost:4000/web/services/2020/04/08/REST.html" rel="alternate" type="text/html" title="REST Architecture Review" /><published>2020-04-08T00:00:00-04:00</published><updated>2020-04-08T00:00:00-04:00</updated><id>http://localhost:4000/web/services/2020/04/08/REST</id><content type="html" xml:base="http://localhost:4000/web/services/2020/04/08/REST.html">&lt;h1 id=&quot;rest-architecture&quot;&gt;REST Architecture&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Allow the manipulation of web service data that is in textua format&lt;/li&gt;
  &lt;li&gt;Uses predefined set of stateless operations&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;there-are-6-guiding-constraints-for-restful-systems&quot;&gt;There are 6 guiding constraints for RESTful systems.&lt;/h3&gt;

&lt;h4 id=&quot;client-server-architecture&quot;&gt;Client-server architecture&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Separate user interface from data storage
    &lt;ul&gt;
      &lt;li&gt;Improves portability, scalability, and allows both components to evolve separately.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;statelessness&quot;&gt;Statelessness&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Each request made by the client has all the information needed to process the request.&lt;/li&gt;
  &lt;li&gt;No information is needed to be stored on the server between requests&lt;/li&gt;
  &lt;li&gt;Single states are passed between different serverside services&lt;/li&gt;
  &lt;li&gt;Clients requests are &lt;em&gt;in transition&lt;/em&gt; while they are waiting to become the current state&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cacheability&quot;&gt;Cacheability&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Clients and intermediares can cache responses&lt;/li&gt;
  &lt;li&gt;Responses must define their cacheability&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;layered-system&quot;&gt;Layered system&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Clients are unable to tell what part of the server they are connected to&lt;/li&gt;
  &lt;li&gt;Allows for proxies, shared caches, security&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;code-on-demand&quot;&gt;Code on demand&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Servers can change client functionality by enabling the use of executable code&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;uniform-interface&quot;&gt;Uniform Interface&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Constraints:
    &lt;ul&gt;
      &lt;li&gt;Resource Identifiaction in requests. Servers can give out different data formats(HTML, XML, JSON) that are requested by the client by identifers (URIs).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Resource manipulation through representations
    &lt;ul&gt;
      &lt;li&gt;Representations passed to the client should be complete and allow modification&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Self-descriptive messages
    &lt;ul&gt;
      &lt;li&gt;Messages should also define how they should be processed&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HATEOAS
    &lt;ul&gt;
      &lt;li&gt;Hypermedia as the engine of application state&lt;/li&gt;
      &lt;li&gt;Dynamic access of server data through hyperlinks&lt;/li&gt;
      &lt;li&gt;REST application will have a root URI requests are made to. Responses in turn will provide new links or other actions that are available to the client.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">REST Architecture</summary></entry><entry><title type="html">LeetCode 30-Day Challenge Part 1: Bit Manipulation</title><link href="http://localhost:4000/leetcode/2020/04/06/LeetCode-1.html" rel="alternate" type="text/html" title="LeetCode 30-Day Challenge Part 1: Bit Manipulation" /><published>2020-04-06T00:00:00-04:00</published><updated>2020-04-06T00:00:00-04:00</updated><id>http://localhost:4000/leetcode/2020/04/06/LeetCode-1</id><content type="html" xml:base="http://localhost:4000/leetcode/2020/04/06/LeetCode-1.html">&lt;h1 id=&quot;leetcode-30-days-of-coding-part-1&quot;&gt;LeetCode 30 Days of Coding Part 1&lt;/h1&gt;
&lt;h3 id=&quot;leetcode-recently-released-a-30-day-contest-for-completing-coding-challenges&quot;&gt;LeetCode recently released a 30 day contest for completing coding challenges&lt;/h3&gt;
&lt;p&gt;While some of these challenges are just different iterations on common algorithms, I have found this particularly useful for testing out how I would solve these problems in different programming languages. For the most part these algorithms can be implemented in the same way across languages outside obvious language particular features. One of the cool things about this though is that sometimes you can gleam really interesting ways of tackling problems. I will be completing the entire 30 day challenge and use this series of blog posts to highlight some of the more interesting techniques. I will be completing the challenge in both python and c++. For python I am mostly looking at writing code in the most pythonic way I can. For c++ the focus will be on understanding the changes in speed and memory allocation across implementations.&lt;/p&gt;

&lt;p&gt;Despite being challenging I think the study of algorithms is one of the most beautiful areas of research in computer science. If you understand algorithms well, it allows you as a programmer to leverage the resources you have to better suit your problems. One of the hallmarks of modern NLP and deep learning  is the massive amount of data required for creating models. The large amount of data and the size of your models can drastically slow down performance, so optimization is integral for research and even more important for putting models into production. There is a growing body of research around creating smaller models and using less data to create better systems. I hope some of the skills I curate during this challenge will help me on my journey as I learn to apply NLP in some more niche areas like embedded systems. Either way I am enjoying myself. Cheers.&lt;/p&gt;

&lt;h2 id=&quot;challenge-1-single-number&quot;&gt;Challenge 1: Single Number&lt;/h2&gt;
&lt;h3 id=&quot;bit-manipulation-in-c&quot;&gt;Bit Manipulation in C++&lt;/h3&gt;
&lt;p&gt;One of the more interesting solutions I have come across in the LeetCode Challenge has been uses for bit manipulation. The XOR operator in c++ operates on bits. The XOR operator compares two bit values and returns 1 if either values are 1 but 0 if both values are one. We will see how this can be leverage to find a unique number in an array of numbders&lt;/p&gt;

&lt;h4 id=&quot;challenge&quot;&gt;Challenge:&lt;/h4&gt;
&lt;p&gt;Given a &lt;strong&gt;non-empty&lt;/strong&gt; array of integers, every element appears &lt;em&gt;twice&lt;/em&gt; except for one. Find that single one.&lt;/p&gt;

&lt;h3 id=&quot;naive-solution&quot;&gt;Naive Solution&lt;/h3&gt;
&lt;p&gt;The naive solution to this problem is pretty straight forward. You first initialize an unordered map and then iterate over the list. For each element in the array if the map contains the number as a key its value is incremented. At the end of the initial for-loop you then iterate over the map and find the key that only has a value of 1.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
using namespace std;

class NaiveSolution {
public:
    int singleNumber(vector&amp;lt;int&amp;gt;&amp;amp; nums) {
        int n = nums.size();
        unordered_map &amp;lt;int, int&amp;gt; count_map;
        for (int i = 0; i &amp;lt; n; i++)
            count_map[nums[i]]++;
        for (int i = 0; i &amp;lt; n; i++)
            if (count_map[nums[i]]==1)
                return nums[i];
                
        return 0;
    }
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;xor-bit-manipulation-solution&quot;&gt;XOR Bit Manipulation Solution&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class BitWiseSolution {
public:
    int singleNumber(vector&amp;lt;int&amp;gt;&amp;amp; nums) {
    int a = 0;
    for (int i : nums) {
        a ^= i;
    }
    return a;
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;At first site one can see a few advantages in this solution. For one thing, no memory is allocated to create a map. Also, while both versions have O(n) runtime the XOR solution only uses a single loop. During the XOR operation each item in the list compared and the bit representation of &lt;strong&gt;a&lt;/strong&gt; is changed accordingly.&lt;/p&gt;

&lt;p&gt;To understand what is going on let’s look at a toy example with the list [1,2,10,2,10].
For each of the 5 iterations we will look at the value of 16-bit version of &lt;strong&gt;a&lt;/strong&gt; :&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Array Index&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;a&lt;/strong&gt; 16-Bit Value&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;a&lt;/strong&gt; Integer Value&lt;/th&gt;
      &lt;th&gt;Array Value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0000000000000001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0000000000000011&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0000000000001001&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0000000000001011&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0000000000000001&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It is interesting to note though that there are problems with both versions, specifically in the case of having multiple unique numbers. The naive solution will return the first value in the map that only appears once, while the bitwise solution will return the XOR equivalent of the individual numbers with all the duplicates removed. This is why it is important to go through test cases to fully understand the behavior of your code. The Naive solution will always return at least one unique number but the bitwise will return whatever integer results from XOR operation.&lt;/p&gt;</content><author><name></name></author><summary type="html">LeetCode 30 Days of Coding Part 1 LeetCode recently released a 30 day contest for completing coding challenges While some of these challenges are just different iterations on common algorithms, I have found this particularly useful for testing out how I would solve these problems in different programming languages. For the most part these algorithms can be implemented in the same way across languages outside obvious language particular features. One of the cool things about this though is that sometimes you can gleam really interesting ways of tackling problems. I will be completing the entire 30 day challenge and use this series of blog posts to highlight some of the more interesting techniques. I will be completing the challenge in both python and c++. For python I am mostly looking at writing code in the most pythonic way I can. For c++ the focus will be on understanding the changes in speed and memory allocation across implementations.</summary></entry></feed>